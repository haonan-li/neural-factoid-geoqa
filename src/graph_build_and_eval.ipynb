{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #preprocessing\n",
    "# with open('gold_label') as f:\n",
    "#     gold_labels = f.readlines()\n",
    "# gold_questions = [gold_labels[2*i] for i in range(200)]\n",
    "# gold_questions = list(map(lambda x: x.replace('\\t',' '), gold_questions))\n",
    "# print (gold_questions)\n",
    "# with open('gold_question','w') as f:\n",
    "#     for question in gold_questions:\n",
    "#         f.write(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../data/DM.sdp') as f:\n",
    "    corpus = f.read()\n",
    "    \n",
    "with open('../data/gold_graph') as f:\n",
    "    gold_graphs = json.load(f)[100:]\n",
    "    \n",
    "with open('../data/bert_graph') as f:\n",
    "    bert_graphs = json.load(f)\n",
    "    \n",
    "# with open('../data/gold_label') as f:\n",
    "#     gold_labels = f.read()[200:]\n",
    "\n",
    "# with open('../data/result/bert_label') as f:\n",
    "#     bert_labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dms = corpus.split('\\n\\n')[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dm_to_graph(dm,nodes):\n",
    "    # build word to node map\n",
    "    anchor = []\n",
    "    for row in dm:\n",
    "        if row[5] == '+':\n",
    "            anchor.append(row[0])\n",
    "\n",
    "    # create all_edges without heuristic\n",
    "    all_edges = set()\n",
    "    other_edges = set()\n",
    "    for row in dm:\n",
    "        arcs = row[7:]\n",
    "        for arc_num in range(len(arcs)):\n",
    "            node_from = dm[int(anchor[arc_num])-1][2]\n",
    "            node_to = row[2]\n",
    "            word_from = dm[int(anchor[arc_num])-1]\n",
    "            word_to = row\n",
    "            # word-level edges\n",
    "            if arcs[arc_num] != '_':\n",
    "                if node_from == node_to:\n",
    "                    continue\n",
    "                elif type(node_from)==int and type(node_to)==int:\n",
    "                    all_edges.add((node_from, node_to, arcs[arc_num]))\n",
    "                # at least one word is not a node\n",
    "                else:\n",
    "                    other_edges.add((node_from, node_to, arcs[arc_num]))\n",
    "                    #print (node_from, node_to)\n",
    "    # uncomment to disable heuristic\n",
    "    # return all_edges.union(other_edges)\n",
    "    \n",
    "    # heuristic begin\n",
    "    # ------------------------------------------------------------#\n",
    "    # if some nodes are connected by other_edges, add it,\n",
    "    for edge in other_edges:\n",
    "        for e in other_edges:\n",
    "            if edge != e and edge[0] == e[0] and type(edge[1])==int and type(e[1])==int:\n",
    "                if edge[2] == \"ARG1\" or e[2] == 'ARG2':\n",
    "                    all_edges.add((edge[1],e[1],''))\n",
    "                else:\n",
    "                    all_edges.add((e[1],edge[1],''))\n",
    "            if edge != e and edge[0] == e[1] and type(edge[1])==int and type(e[0])==int:\n",
    "                    all_edges.add((e[0],edge[1],''))\n",
    "    \n",
    "    # modify all_edges use some rule\n",
    "    dm_edges = set()\n",
    "    \n",
    "    # step 1 wh-word\n",
    "    flag=False\n",
    "    for edge in list(all_edges):\n",
    "        # if edge from wh-word, add it\n",
    "        if nodes[edge[0]]['code'] == 'num' or nodes[edge[0]]['code'].isdigit():\n",
    "            flag = True\n",
    "            # if the edge label is 'loc', find the anchor, merge it\n",
    "            if edge[2] == 'loc':\n",
    "                for e in list(all_edges):\n",
    "                    if e[0] == edge[1] and e[2]=='ARG2':\n",
    "                        all_edges.remove(e)\n",
    "                        all_edges.remove(edge)\n",
    "                        edge = (edge[0],e[1],'ARG1')\n",
    "                        dm_edges.add(edge)\n",
    "            else:\n",
    "                all_edges.remove(edge)\n",
    "                dm_edges.add(edge)\n",
    "    if not flag:\n",
    "        for i,node in enumerate(nodes):\n",
    "            if node['code'] == 'num' or node['code'].isdigit():\n",
    "                # check other node, whether some nodes link wh-word with another node\n",
    "                for edge in other_edges:\n",
    "                    if edge[1]==i and edge[2]=='ARG1':\n",
    "                        for e in other_edges:\n",
    "                            if e[0] == edge[0] and e[2] == 'ARG2':\n",
    "                                flag = True\n",
    "                                dm_edges.add((edge[1],e[1],edge[0]))\n",
    "                # else add wh-word with its nearest node\n",
    "                if not flag:    \n",
    "                    dm_edges.add((i,i+1,'ARG1'))\n",
    "    for edge in list(dm_edges):\n",
    "        if (nodes[edge[0]]['code'] == 'num' or nodes[edge[0]]['code'].isdigit()) and nodes[edge[0]]['text'][:2] in ['Is', 'Do', 'Ar']:\n",
    "            dm_edges.remove(edge)\n",
    "        \n",
    "                    \n",
    "    for edge in list(all_edges):\n",
    "        if (nodes[edge[0]]['code'] == 'num' or nodes[edge[0]]['code'].isdigit()) and nodes[edge[0]]['text'][:2] in ['Is', 'Do', 'Ar']:\n",
    "            all_edges.remove(edge)\n",
    "        # if edge is from r to n or t, add it\n",
    "        if nodes[edge[0]]['code'] == 'r' and nodes[edge[1]]['code'] in ['n','t']:\n",
    "            all_edges.remove(edge)\n",
    "            dm_edges.add(edge)\n",
    "            \n",
    "    for edge in list(all_edges):\n",
    "        # edge from r to d, check the label (ARG1 should be refine)\n",
    "        if nodes[edge[0]]['code'] == 'r' and nodes[edge[1]]['code'] == 'd' and edge[2]=='ARG1':\n",
    "            flag = True\n",
    "            for e in dm_edges:\n",
    "                if e == (e[0],_,'ARG2'):\n",
    "                    flag = True\n",
    "                    break\n",
    "            if flag:\n",
    "                all_edges.remove(edge)\n",
    "                for i in range(edge[0],0,-1):\n",
    "                    if nodes[i]['code'] in ['t','n']:\n",
    "                        dm_edges.add((edge[0], i, edge[2]))\n",
    "\n",
    "    for edge in list(all_edges):\n",
    "        # edge from r to d, check the label (ARG2 is ok, but check if ARG1 exist)\n",
    "        if nodes[edge[0]]['code'] == 'r' and nodes[edge[1]]['code'] == 'd' and edge[2]=='ARG2':\n",
    "            all_edges.remove(edge)\n",
    "            dm_edges.add(edge)\n",
    "            for e in list(dm_edges):\n",
    "                # remove the wrong label\n",
    "                if e[0]==edge[0] and e[2]!='ARG1':\n",
    "                    dm_edges.remove(e)\n",
    "                    break\n",
    "            for e1 in list(dm_edges):\n",
    "                for e2 in list(dm_edges):\n",
    "                    if e1[0]==e2[0] and e1[2]=='ARG1' and e2[2]=='ARG2':\n",
    "                        dm_edges.add((edge[0],e1[0],'ARG1'))\n",
    "                        \n",
    "    # heuristic end\n",
    "    # ------------------------------------------------------------#\n",
    "    \n",
    "    #     print (f'dm_edges: {dm_edges}')\n",
    "    #     print (f'remain: {all_edges}')\n",
    "\n",
    "    return dm_edges.union(all_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_true_edge(nodes,set1):\n",
    "    set1 = set(list(map(lambda x: (nodes[x[0]]['text'], nodes[x[1]]['text'], x[2]) if type(x[0])==int and type(x[1])==int else x, list(set1))))\n",
    "    return set1\n",
    "\n",
    "y,y_pred = [],[]\n",
    "for dm,gold_graph,bert_graph in zip(dms, gold_graphs, bert_graphs):\n",
    "    dm = list(filter(lambda x: x and x[0]!='#', dm.split('\\n')))\n",
    "    dm = list(map(lambda x: x.split('\\t'), dm))\n",
    "    \n",
    "    gold_nodes = gold_graph['nodes']\n",
    "    bert_nodes = bert_graph['nodes']\n",
    "    sentence = gold_graph['sentence']\n",
    "    # build gold edges\n",
    "    gold_edges = set()\n",
    "    for node_num,node in enumerate(bert_nodes):\n",
    "        # assign dm[2] to node_num\n",
    "        for i in range(node['start'],node['end']):\n",
    "            dm[i][2] = node_num\n",
    "    for node_num,node in enumerate(gold_nodes):\n",
    "        if node['arg1'][0]!=-1:\n",
    "            gold_edges.add((node_num,node['arg1'][0],'ARG1'))\n",
    "        if node['arg2'][0]!=-1:\n",
    "            gold_edges.add((node_num,node['arg2'][0],'ARG2'))\n",
    "\n",
    "    assert len(sentence.split()) == len(dm)\n",
    "    pred_edges = dm_to_graph(dm, bert_nodes)\n",
    "    y.append(to_true_edge(gold_nodes,gold_edges))\n",
    "    y_pred.append(to_true_edge(bert_nodes,pred_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_graph(set1,set2):\n",
    "    set1 = set(list(map(lambda x: (x[0],x[1]), set1)))\n",
    "    set2 = set(list(map(lambda x: (x[0],x[1]), set2)))\n",
    "    return set1==set2\n",
    "\n",
    "def edge_stats(set1,set2):\n",
    "    set1 = set(list(map(lambda x: (x[0],x[1]), set1)))\n",
    "    set2 = set(list(map(lambda x: (x[0],x[1]), set2)))\n",
    "    return len(set1.intersection(set2)), len(set1), len(set2)\n",
    "    \n",
    "def eval(y,y_pred):\n",
    "    # edge level\n",
    "    tp, t, p = 0, 0, 0\n",
    "    for yy,yy_pred in zip(y,y_pred):\n",
    "        tp1, t1, p1 = edge_stats(yy,yy_pred)\n",
    "        tp += tp1\n",
    "        t += t1\n",
    "        p += p1\n",
    "    precision = tp/p\n",
    "    recall = tp/t\n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "    print(f'Edge_level, p:{100*precision}, r:{100*recall}, f1:{100*f1}')\n",
    "    # graph level\n",
    "    tp = 0\n",
    "    for (yy,yy_pred) in zip(y,y_pred):\n",
    "        tp += same_graph(yy,yy_pred)\n",
    "    print(f'Graph_level acc: {100*tp/len(y)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge_level, p:69.92084432717678, r:71.62162162162163, f1:70.76101468624833\n",
      "Graph_level acc: 44.0\n"
     ]
    }
   ],
   "source": [
    "eval(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build random baseline\n",
    "import random\n",
    "y_pred = []\n",
    "for gold_graph in gold_graphs:\n",
    "    gold_nodes = gold_graph['nodes']\n",
    "    pred = []\n",
    "    for st in range(len(gold_nodes)):\n",
    "        for ed in range(len(gold_nodes)):\n",
    "            if st!=ed:\n",
    "                if random.randint(0,1)==1:\n",
    "                    pred.append((st,ed,'RD'))\n",
    "    y_pred.append(to_true_edge(gold_nodes, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge_level, p:15.067340067340067, r:48.37837837837838, f1:22.978177150192554\n",
      "Graph_level acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "eval(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "# pipelined result (integrate manual evaluation)\n",
    "final_acc = 0\n",
    "with open('../data/mannual_evaluation/final.txt') as f:\n",
    "    manual = f.readlines()\n",
    "for yy, yy_pred, m in zip(y,y_pred,manual):\n",
    "    if same_graph(yy,yy_pred) and m.strip() == 'True':\n",
    "        final_acc += 1\n",
    "print(final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Did not use initialization regex that was passed: .*bias_ih.*\n",
      "Did not use initialization regex that was passed: .*bias_hh.*\n",
      "Did not use initialization regex that was passed: .*weight_hh.*\n",
      "Did not use initialization regex that was passed: .*weight_ih.*\n"
     ]
    }
   ],
   "source": [
    "# build dep_baseline\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "dep_predictor = Predictor.from_path(\"/home/haonanl5/tools/allennlp_model/biaffine-dependency-parser-ptb-2018.08.23.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,y_pred = [],[]\n",
    "for gold_graph in gold_graphs:\n",
    "    pred_edges = set()\n",
    "    gold_nodes = gold_graph['nodes']\n",
    "    sentence = gold_graph['sentence']\n",
    "    dep = dep_predictor.predict(sentence)['predicted_heads']\n",
    "    dep_to_node = [-1 for _ in range(len(dep))]\n",
    "    # build gold edges\n",
    "    for node_num,node in enumerate(gold_nodes):\n",
    "        for i in range(node['start'],node['end']):\n",
    "            dep_to_node[i] = node_num\n",
    "    for ed,st in enumerate(dep):\n",
    "        if st == 0:\n",
    "            continue\n",
    "        node_from = dep_to_node[st-1]\n",
    "        node_to = dep_to_node[ed]\n",
    "        if node_from == node_to:\n",
    "            continue\n",
    "        word_from = -1 if node_from==-1 else gold_nodes[node_from]['text']\n",
    "        word_to = -1 if node_to==-1 else gold_nodes[node_to]['text']\n",
    "        pred_edges.add((word_from, word_to, ''))\n",
    "    \n",
    "    gold_edges = set()\n",
    "    for node_num,node in enumerate(gold_nodes):\n",
    "        if node['arg1'][0]!=-1:\n",
    "            gold_edges.add((node_num,node['arg1'][0],'ARG1'))\n",
    "        if node['arg2'][0]!=-1:\n",
    "            gold_edges.add((node_num,node['arg2'][0],'ARG2'))\n",
    "        \n",
    "    y.append(to_true_edge(gold_nodes,gold_edges))\n",
    "    y_pred.append(pred_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge_level, p:26.29695885509839, r:39.729729729729726, f1:31.646932185145317\n",
      "Graph_level acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "eval(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
